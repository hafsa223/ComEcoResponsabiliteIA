# ComEcoResponsabiliteIAÉvaluation comparative de modèles Deep Learning et leur impact écologique
## Objectif du projet
Ce projet a pour objectif d’évaluer et de comparer plusieurs modèles d’apprentissage supervisé – un modèle classique SVM et trois architectures de deep learning (CNN, DenseNet et VGG, à la fois en version pré-entraînée et entraînée depuis zéro) – sur des critères de performance et d’impact écologique. Plus précisément, chaque modèle est comparé selon sa précision de classification, son temps d’entraînement, et les émissions de CO₂ générées durant l’entraînement. L’ambition est de mettre en évidence les compromis (trade-offs) entre la performance prédictive d’un modèle et son coût environnemental (mesuré via le temps de calcul et l’empreinte carbone). Pour ce faire, l’outil CodeCarbon est utilisé afin de mesurer la consommation énergétique et les émissions carbone associées à chaque expérience d’entraînement.
## Contexte
Ce projet s’inscrit dans une démarche de Data Science responsable, dans le cadre du Master Data Science à Ynov Lyon. L’essor des modèles de Deep Learning s’accompagne d’une forte augmentation de la consommation d’énergie des calculs, soulevant des préoccupations quant à leur impact écologique. Former des réseaux de neurones profonds peut nécessiter des ressources informatiques intensives (CPU/GPU) pendant de longues durées, ce qui se traduit par une consommation électrique significative et des émissions de CO₂ correspondantes. Il devient donc crucial de sensibiliser les praticiens aux coûts environnementaux cachés de l’IA et de promouvoir des approches plus soutenables. Dans ce contexte, ce projet compare différents modèles de complexité variée afin d’illustrer comment le choix d’un modèle peut influencer non seulement la précision obtenue, mais aussi l’empreinte carbone de son entraînement.
## Structure du projet
Voici la structure des principaux fichiers et répertoires du projet :
train_et_track.py – Script principal permettant de lancer l’entraînement des modèles et de suivre en direct les émissions de CO₂ grâce à CodeCarbon. C’est ce script qui entraîne successivement le SVM et les réseaux de neurones, tout en enregistrant le temps d’exécution et les mesures d’impact carbone.
visualize_results.py – Script Python de visualisation des résultats. Il charge les métriques enregistrées (précision, temps, émissions) pour chaque modèle et génère des graphiques comparatifs (courbes ou histogrammes) illustrant les performances et l’impact écologique de chaque approche.
models/ – Répertoire contenant les définitions des modèles et éventuellement les poids entraînés. Par exemple, on y trouve les architectures du CNN personnalisé, de DenseNet, de VGG non pré-entraîné, ainsi que le chargement du VGG pré-entraîné (poids ImageNet) si nécessaire.
results/ – Répertoire de sortie où sont stockés les résultats et artefacts produits par les scripts. On y retrouve par exemple les fichiers de logs (y compris les données d’émissions CO₂ enregistrées par CodeCarbon), les métriques finales des modèles, ainsi que les graphiques générés par visualize_results.py.
data_loader.py – Script utilitaire pour le chargement et le prétraitement des données. Il gère l’import du jeu de données de classification d’images utilisé pour l’expérience, applique les transformations nécessaires (par ex. conversion en niveaux de gris, redimensionnement, duplication de canaux pour compatibilité avec certains modèles) et prépare les dataloaders pour l’entraînement et le test des modèles.
poster.png – Affiche synthétique du projet (format PNG) réalisée via Canva. Ce poster résume visuellement l’objectif, la méthodologie et les principaux résultats obtenus, dans un format adapté à une communication académique ou événementielle.
rapport.pdf – Rapport écrit du projet (format PDF). Il s’agit d’un document plus détaillé expliquant le contexte, la démarche, la configuration expérimentale et l’analyse complète des résultats. Le rapport fournit également des références sur l’impact environnemental de l’IA et replace les observations du projet dans un contexte plus large.
## Installation
Pour reproduire ce projet, veuillez suivre les étapes d’installation ci-dessous :
Cloner le dépôt GitHub : Téléchargez le code source du projet sur votre machine, soit en clonant le dépôt via git clone, soit en téléchargeant l’archive ZIP depuis GitHub.
Créer un environnement virtuel : Il est recommandé d’utiliser un environnement virtuel Python (par exemple avec venv ou conda) afin d’isoler les dépendances du projet. Par exemple :

python3 -m venv env
source env/bin/activate  # Sur Linux/Mac
env\Scripts\activate     # Sur Windows
Installer les dépendances : Assurez-vous d’avoir Python 3.7 ou plus récent, puis installez les packages requis. Si un fichier requirements.txt est fourni, vous pouvez exécuter :
 
pip install -r requirements.txt
Sinon, installez manuellement les principales bibliothèques utilisées. Les dépendances majeures incluent notamment :
CodeCarbon (suivi des émissions CO₂ pendant l’exécution du code)
PyTorch et Torchvision (entrainement des réseaux de neurones CNN, DenseNet, VGG)
scikit-learn (modèle SVM et utilitaires d’évaluation)
matplotlib / seaborn (visualisation des résultats sous forme de graphiques)
pandas (pour le chargement/enregistrement des données de résultats)
Vérifier l’installation : Après l’installation, vous pouvez lancer Python et importer les modules ci-dessus pour vérifier que tout est correctement installé, par exemple : import torch, sklearn, codecarbon. Veillez également à disposer d’un jeu de données approprié (fourni ou téléchargeable) si celui-ci n’est pas inclus dans le dépôt.
## Exécution
Une fois l’environnement configuré, vous pouvez exécuter les différentes étapes du projet comme suit :
Lancement de l’entraînement et du suivi carbone : Exécutez le script principal d’entraînement train_et_track.py depuis votre terminal ou votre IDE préféré. Par exemple :

python train_et_track.py

Ce script va successivement entraîner chaque modèle (SVM, CNN, DenseNet, VGG non pré-entraîné, VGG pré-entraîné). Pour chaque entraînement, il mesure le temps écoulé et utilise CodeCarbon pour suivre la consommation d’énergie et estimer les émissions de CO₂ émises. Pendant l’exécution, des informations de progression et des mesures peuvent s’afficher dans la console. À la fin de chaque entraînement, les métriques (précision atteinte sur le jeu de test, durée totale d’exécution, émissions carbone cumulées) sont enregistrées dans le répertoire results/ (par exemple dans un fichier CSV ou un log).
Suivi des émissions carbone : Le suivi de l’impact écologique est automatisé via la librairie CodeCarbon
file-631xuxkdc6av5txcxsvwvv
. Aucune action spécifique n’est requise de la part de l’utilisateur pendant l’entraînement, si ce n’est de patienter jusqu’à la fin. CodeCarbon se charge de calculer en arrière-plan la consommation énergétique du processus Python et d’en déduire les émissions de CO₂ équivalentes en fonction de la localisation par défaut. Les résultats détaillés (par exemple les grammes ou kilogrammes de CO₂ émis) sont soit affichés dans la console, soit consignés dans un fichier (tel que emissions.csv) au sein du dossier results/. Vous pourrez consulter ces valeurs après coup pour chaque modèle évalué.
Génération des graphiques de résultats : Une fois tous les modèles entraînés et les résultats chiffrés disponibles, vous pouvez exécuter le script de visualisation :


python visualize_results.py


Ce script va charger les données de performance et d’émissions précédemment sauvegardées (assurez-vous d’avoir exécuté train_et_track.py au préalable), puis tracer plusieurs graphes comparatifs. Typiquement, il génère des histogrammes ou courbes pour : (a) la précision de chaque modèle, (b) le temps d’entraînement de chaque modèle, (c) les émissions de CO₂ de chaque modèle. Les graphiques seront soit affichés dans une fenêtre interactive, soit sauvegardés en images (PNG) dans le répertoire results/ (selon l’implémentation choisie). Ces visualisations permettent de comparer d’un coup d’œil les performances et l’impact écologique des modèles. Vous pourrez par exemple observer quel modèle est le plus précis, ou lequel a l’empreinte carbone la plus faible, etc.
Analyse des résultats : À ce stade, toutes les données nécessaires sont disponibles pour interpréter les résultats. Vous pouvez consulter la section Résultats ci-dessous pour un résumé, ou vous référer au fichier rapport.pdf pour une analyse détaillée. Les graphes générés par visualize_results.py peuvent également être utilisés pour créer des supports de communication (ils ont d’ailleurs été intégrés au poster fourni).
## Résultats
Les expériences menées ont permis de recueillir, pour chaque modèle, la précision obtenue sur le jeu de test, le temps d’entraînement complet, et les émissions carbone correspondantes. Le tableau ci-dessous résume ces résultats observés :
Modèle	Précision (test)	Temps d’entraînement (s)	Émissions CO₂ (kg CO₂eq)
SVM (linéaire)	0,184 (~18,4 %)	72,38	0,000135
DenseNet (léger)	0,309 (~30,9 %)	5,98	0,000011
CNN (3 couches)	0,507 (~50,7 %)	17,19	0,000032
VGG (pré-entraîné)	0,558 (~55,8 %)	301,62	0,000563
VGG (from scratch)	0,522 (~52,2 %)	24,02	0,000045

## Observations :
 Les résultats montrent que le modèle VGG pré-entraîné est celui qui atteint la meilleure précision (environ 55,8 % de bonnes prédictions) sur le jeu de test. En revanche, cette performance élevée s’accompagne du temps d’entraînement le plus long (plus de 5 minutes sur CPU) et de l’empreinte carbone la plus importante, avec environ 5,6×10^-4 kg de CO₂ émis. À l’opposé, le petit réseau DenseNet s’avère être le plus sobre énergétiquement : il s’entraîne en à peine 6 secondes et n’émet que ~1.1×10^-5 kg de CO₂, soit 10 fois moins que VGG. Ce modèle sacrifie cependant la précision (≈30,9 %) au profit d’une efficacité écologique maximale. Le CNN personnalisé obtient une précision intermédiaire (~50,7 %) pour un temps de calcul raisonnable (17 secondes). Le SVM linéaire, bien que très rapide à prédire, requiert un temps d’entraînement non négligeable (~72 s) et fournit la précision la plus faible du lot (~18,4 %), ce qui en fait un point de comparaison intéressant mais moins performant sur ce jeu de données d’images. Enfin, la version VGG entraînée depuis zéro atteint une précision de 52,2 % en ~24 secondes, ce qui est légèrement moins précis que le VGG pré-entraîné tout en étant beaucoup plus rapide à entraîner. Ce constat peut sembler contre-intuitif, mais s’explique par le fait que dans notre configuration (sans GPU, petit dataset), le surcoût de calcul d’un grand réseau non entraînable dépasse le bénéfice initial du transfert d’apprentissage. Ces résultats illustrent concrètement les compromis entre performance et coût écologique : le modèle le plus précis n’est pas le plus économe, et vice-versa.
## Poster et rapport
Ce dépôt s’accompagne de deux documents clés qui complètent le code source :
Poster du projet (poster.png) – Une affiche au format A2 (exportée depuis Canva) qui synthétise le contexte, la démarche et les résultats du projet. Le poster présente visuellement les informations majeures : objectif, méthodologie (schéma des modèles évalués, description du jeu de données), résultats chiffrés et graphiques comparatifs, ainsi que quelques informations générales sur l’impact écologique de l’IA pour sensibiliser le lecteur. Ce support a été conçu dans un but de communication pédagogique, par exemple pour être affiché lors d’une session de posters académiques ou partagé en ligne.
Rapport PDF (rapport.pdf) – Un document d’une dizaine de pages détaillant l’ensemble du projet. Le rapport décrit en profondeur le contexte et les motivations (avec des références sur l’empreinte carbone du numérique), la méthodologie expérimentale (préparation des données, choix des hyperparamètres, conditions d’exécution sans GPU, etc.), puis présente et analyse les résultats obtenus. Vous y trouverez également les réflexions sur les choix techniques (par exemple, pourquoi une recherche d’hyperparamètres exhaustive a été évitée pour limiter les calculs), et une conclusion discute des enseignements tirés. Le poster et le rapport sont complémentaires : le poster donne un aperçu visuel rapide, tandis que le rapport fournit les détails et le raisonnement scientifique sous-jacent.
Pour consulter ces documents, vous pouvez ouvrir le fichier PNG directement dans votre visualiseur d’images, et le PDF dans votre lecteur de PDF préféré. Ils constituent une part intégrante du projet et offrent un éclairage supplémentaire au-delà du simple code.
## Conclusion
Cette étude comparative met en lumière les compromis entre performance et impact écologique dans le domaine du Machine Learning. Les principaux enseignements à retenir sont les suivants :
Il n’existe pas de modèle parfait qui optimise à la fois la précision et l’empreinte carbone. Un modèle plus complexe (comme VGG) peut offrir une meilleure performance en termes de précision, mais au prix d’un coût énergétique plus élevé. Inversement, un modèle allégé (comme DenseNet dans notre cas) peut être extrêmement économe en énergie, mais fournir une précision moindre. Le choix du modèle dépendra donc de la priorité du projet (performance maximale vs. sobriété énergétique) et du cas d’usage.
Le transfert d’apprentissage (utilisation de modèles pré-entraînés) est souvent avancé comme une méthode pour économiser du temps de calcul. Toutefois, ce projet montre que son intérêt doit être relativisé en fonction du contexte matériel et des données. Sur un petit jeu de données et sans accélération matérielle (GPU), exploiter un grand modèle pré-entraîné peut, paradoxalement, coûter plus de temps et d’énergie que d’entraîner un modèle plus simple depuis zéro. Il est donc important d’adapter la stratégie au contexte pour minimiser l’impact écologique inutile.
Les différences d’émissions carbone absolues mesurées dans ce projet sont faibles (de l’ordre de milligrammes de CO₂) car les expériences ont été réalisées à petite échelle. Néanmoins, ces résultats servent de preuve de concept : à plus grande échelle (données massives, modèles profonds entraînés sur GPU pendant des jours), les écarts seraient sans commune mesure. Ainsi, intégrer dès maintenant la dimension écologique dans l’évaluation des modèles permet de prendre conscience de cet impact latent et d’encourager des pratiques d’IA plus durables.
En conclusion, ce projet renforce l’idée que la performance d’un modèle de Machine Learning ne devrait pas être évaluée isolément, mais en tenant compte de son coût environnemental. Les développeurs et data scientists sont encouragés à considérer ces aspects dans leurs travaux, par exemple en monitorant systématiquement l’empreinte carbone de leurs entraînements (grâce à des outils comme CodeCarbon) et en cherchant des alternatives plus efficientes lorsque cela est possible. C’est en multipliant ce genre d’initiatives et de prises de conscience que la communauté pourra progresser vers une IA éco-responsable, conciliant innovation et respect de l’environnement.
## Licence et crédits
Ce projet a été réalisé dans un cadre académique (projet de fin de module au sein du Master Data Science, Ynov Campus Lyon) et est mis à disposition à des fins pédagogiques et de recherche. L’auteure du projet est Hafsa Moumni, étudiante en Master 2 Data Science. Le code, les scripts et les documents fournis sont libres d’être réutilisés ou adaptés dans un contexte éducatif ou expérimental, à condition d’en citer la provenance et l’auteure. Ce dépôt n’est pas destiné à un usage commercial ou productif et aucune garantie n’est fournie quant à son fonctionnement en dehors de l’environnement de test. Par ailleurs, ce projet s’est appuyé sur la librairie open-source CodeCarbon pour le suivi des émissions de CO₂ lors des entraînements
file-631xuxkdc6av5txcxsvwvv
. CodeCarbon est un outil développé dans une optique de sensibilisation à l’impact carbone du code informatique : il estime, de manière transparente pour le développeur, la quantité de CO₂ émise en fonction des ressources machine utilisées pendant l’exécution du programme. Un grand merci aux contributeurs de CodeCarbon pour cette initiative précieuse. Enfin, nous soulignons que l’ensemble de ce travail s’inspire de la mouvance actuelle vers une IA plus responsable – nous espérons qu’il contribuera, à son échelle, à promouvoir des pratiques plus durables dans la communauté Machine Learning.